# -*- coding: utf-8 -*-
"""Spark.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DmO474PYWo0Z59bvmJCqpYva3oDpeZsc

# Setup
"""

# Ù†ØµØ¨ Java Ùˆ Spark (Ù†Ø³Ø®Ù‡ Ù¾Ø§ÛŒØ¯Ø§Ø±ØªØ± Ø¨Ø±Ø§ÛŒ Colab)
!apt-get install openjdk-8-jdk-headless -qq > /dev/null
!wget -q https://archive.apache.org/dist/spark/spark-3.1.2/spark-3.1.2-bin-hadoop2.7.tgz
!tar xf spark-3.1.2-bin-hadoop2.7.tgz
!pip install -q findspark

# ØªÙ†Ø¸ÛŒÙ… Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ù…Ø­ÛŒØ·ÛŒ
import os
os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-8-openjdk-amd64"
os.environ["SPARK_HOME"] = "/content/spark-3.1.2-bin-hadoop2.7"

import findspark
findspark.init()

"""# **1-**

# Spark Sec
"""

from pyspark.sql import SparkSession

spark = SparkSession.builder \
    .appName("HeartDiseaseClassification") \
    .getOrCreate()

"""# Dataset

## Ø¯Ø§Ù†Ù„ÙˆØ¯
"""

import kagglehub

# Download latest version
path = kagglehub.dataset_download("redwankarimsony/heart-disease-data")

print("Path to dataset files:", path)

"""## Ù„ÙˆØ¯ Ù„ÙˆÚ©Ø§Ù„"""

df = spark.read.csv("/content/heart_disease_uci.csv", header=True, inferSchema=True)
df.printSchema()
df.show(5)

"""# PreProcess"""

from pyspark.ml.feature import StringIndexer, VectorAssembler
from pyspark.ml import Pipeline

df = df.dropna()
categorical_cols = []
numerical_cols = [col for col in df.columns if col != 'target']

assembler = VectorAssembler(inputCols=numerical_cols, outputCol="features")
pipeline = Pipeline(stages=[assembler])
df_transformed = pipeline.fit(df).transform(df)

df_final = df_transformed.select("features", "target")
df_final.show(5)

from pyspark.sql.functions import col

# Ù…Ø±Ø­Ù„Ù‡ 0: ØªØ¨Ø¯ÛŒÙ„ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ boolean Ø¨Ù‡ Ø±Ø´ØªÙ‡
df = df.withColumn("fbs", col("fbs").cast("string"))
df = df.withColumn("exang", col("exang").cast("string"))

# Ø­Ø°Ù Ø±Ø¯ÛŒÙâ€ŒÙ‡Ø§ÛŒ Ù†Ø§Ù‚Øµ
df = df.dropna()

# Ù„ÛŒØ³Øª Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø¯Ø³ØªÙ‡â€ŒØ§ÛŒ (categorical) Ú©Ù‡ Ø¨Ø§ÛŒØ¯ index Ø¨Ø´Ù†
categorical_cols = ["sex", "cp", "restecg", "slope", "thal", "fbs", "exang", "dataset"]

# Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø¹Ø¯Ø¯ÛŒ (numeric)
numeric_cols = ["age", "trestbps", "chol", "thalch", "oldpeak", "ca"]

# Ù…Ø±Ø§Ø­Ù„ index Ú©Ø±Ø¯Ù†
from pyspark.ml.feature import StringIndexer, VectorAssembler
from pyspark.ml import Pipeline

indexers = [StringIndexer(inputCol=col, outputCol=col + "_idx") for col in categorical_cols]

# ØªØ±Ú©ÛŒØ¨ featureÙ‡Ø§
assembler = VectorAssembler(
    inputCols=[col + "_idx" for col in categorical_cols] + numeric_cols,
    outputCol="features"
)

# pipeline Ø³Ø§Ø®Øª
pipeline = Pipeline(stages=indexers + [assembler])

# Ø§Ø¬Ø±Ø§
df_prepared = pipeline.fit(df).transform(df)

# Ù†Ù‡Ø§ÛŒÛŒâ€ŒØ³Ø§Ø²ÛŒ Ø¯ÛŒØªØ§ÙØ±ÛŒÙ…
df_final = df_prepared.select("features", col("num").alias("label"))
df_final.show(5)

"""# Train / Test : Split"""

# ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
train_data, test_data = df_final.randomSplit([0.8, 0.2], seed=42)

# Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„
from pyspark.ml.classification import RandomForestClassifier
from pyspark.ml.evaluation import MulticlassClassificationEvaluator


rf = RandomForestClassifier(labelCol="label", featuresCol="features")
model = rf.fit(train_data)

# Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ
predictions = model.transform(test_data)

# Ù†Ù…Ø§ÛŒØ´ Ù†ØªØ§ÛŒØ¬
predictions.select("prediction", "label").show(10)

# Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø¯Ù‚Øª
evaluator = MulticlassClassificationEvaluator(labelCol="label", predictionCol="prediction", metricName="accuracy")
accuracy = evaluator.evaluate(predictions)
print(f" Accuracy: {accuracy}")

"""# Eval"""

df_final.groupBy("label").count().show()

from pyspark.ml.evaluation import MulticlassClassificationEvaluator
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report

# Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù…Ø¬Ø¯Ø¯
predictions = model.transform(test_data)

# Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ Ø¯Ø± PySpark
evaluator_accuracy = MulticlassClassificationEvaluator(labelCol="label", predictionCol="prediction", metricName="accuracy")
evaluator_f1 = MulticlassClassificationEvaluator(labelCol="label", predictionCol="prediction", metricName="f1")
evaluator_precision = MulticlassClassificationEvaluator(labelCol="label", predictionCol="prediction", metricName="weightedPrecision")
evaluator_recall = MulticlassClassificationEvaluator(labelCol="label", predictionCol="prediction", metricName="weightedRecall")

acc = evaluator_accuracy.evaluate(predictions)
f1 = evaluator_f1.evaluate(predictions)
prec = evaluator_precision.evaluate(predictions)
rec = evaluator_recall.evaluate(predictions)

print(f" Accuracy        : {acc:.4f}")
print(f" F1 Score        : {f1:.4f}")
print(f" Precision       : {prec:.4f}")
print(f" Recall (Sensitivity): {rec:.4f}")

# Ø§Ø³ØªØ®Ø±Ø§Ø¬ prediction Ùˆ label Ø¨Ù‡ ØµÙˆØ±Øª Ù„ÛŒØ³Øª
y_true = predictions.select("label").toPandas()
y_pred = predictions.select("prediction").toPandas()

# Ù…Ø­Ø§Ø³Ø¨Ù‡ Ùˆ Ù†Ù…Ø§ÛŒØ´ confusion matrix
cm = confusion_matrix(y_true, y_pred, labels=[0,1,2,3,4])
print(" Confusion Matrix:")
print(cm)

# Ø±Ø³Ù… Ú¯Ø±Ø§ÙÛŒÚ©ÛŒ
plt.figure(figsize=(8,6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=[0,1,2,3,4], yticklabels=[0,1,2,3,4])
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix")
plt.show()

print(" Classification Report:")
print(classification_report(y_true, y_pred, digits=3))

"""# Temp to Improve

### Ø¬Ù†Ú¯Ù„ Ø¨Ù‡ØªØ± :
"""

from pyspark.ml.classification import RandomForestClassifier
from pyspark.ml.evaluation import MulticlassClassificationEvaluator
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# 1. ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
train_data, test_data = df_final.randomSplit([0.8, 0.2], seed=42)

# 2. Ù…Ø¯Ù„ Ù‚ÙˆÛŒâ€ŒØªØ± Ø¨Ø§ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ø¨Ù‡ØªØ±
rf = RandomForestClassifier(
    labelCol="label",
    featuresCol="features",
    numTrees=200,               # Ø¯Ø±Ø®Øªâ€ŒÙ‡Ø§ÛŒ Ø¨ÛŒØ´ØªØ± = Ù…Ø¯Ù„ Ù¾Ø§ÛŒØ¯Ø§Ø±ØªØ±
    maxDepth=10,                # Ø¹Ù…Ù‚ Ø¨ÛŒØ´ØªØ± = ØªÙÚ©ÛŒÚ© Ø¨Ù‡ØªØ± Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§
    minInstancesPerNode=2,      # Ú©Ù†ØªØ±Ù„ overfitting
    featureSubsetStrategy="auto", # Ø§Ù†ØªØ®Ø§Ø¨ ÙˆÛŒÚ˜Ú¯ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡ Ø¯Ø± Ù‡Ø± split
    subsamplingRate=0.9         # Ø´Ø¨Ù‡-bagging Ø¨Ø±Ø§ÛŒ ØªÙ†ÙˆØ¹ Ø¨ÛŒØ´ØªØ± Ø¯Ø± Ø¯Ø±Ø®Øªâ€ŒÙ‡Ø§
)
model = rf.fit(train_data)

# 3. Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ
predictions = model.transform(test_data)
predictions.select("prediction", "label").show(10)

# 4. Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ú†Ù†Ø¯Ù…Ø¹ÛŒØ§Ø±ÛŒ Ø¯Ø± PySpark
eval_acc = MulticlassClassificationEvaluator(labelCol="label", predictionCol="prediction", metricName="accuracy")
eval_f1 = MulticlassClassificationEvaluator(labelCol="label", predictionCol="prediction", metricName="f1")
eval_prec = MulticlassClassificationEvaluator(labelCol="label", predictionCol="prediction", metricName="weightedPrecision")
eval_rec = MulticlassClassificationEvaluator(labelCol="label", predictionCol="prediction", metricName="weightedRecall")

print(f" Accuracy       : {eval_acc.evaluate(predictions):.4f}")
print(f" F1 Score       : {eval_f1.evaluate(predictions):.4f}")
print(f" Precision      : {eval_prec.evaluate(predictions):.4f}")
print(f" Recall         : {eval_rec.evaluate(predictions):.4f}")

# 5. Confusion Matrix (Ø¨Ø§ ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ pandas)
y_true = predictions.select("label").toPandas()
y_pred = predictions.select("prediction").toPandas()
cm = confusion_matrix(y_true, y_pred, labels=[0,1,2,3,4])

plt.figure(figsize=(8,6))
sns.heatmap(cm, annot=True, fmt="d", cmap="YlGnBu", xticklabels=[0,1,2,3,4], yticklabels=[0,1,2,3,4])
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix (Enhanced RandomForest)")
plt.show()

"""Ù…Ø­Ø§Ø³Ø¨Ù‡ ÙˆØ²Ù† Ú©Ù„Ø§Ø³ Ù…Ø¹Ú©ÙˆØ³ Ù†Ø³Ø¨Øª Ø¨Ù‡ ØªØ¹Ø¯Ø§Ø¯ Ù†Ù…ÙˆÙ†Ù‡"""

from pyspark.sql import Window
from pyspark.sql.functions import col, count, lit, when

# Ù…Ø­Ø§Ø³Ø¨Ù‡ ØªØ¹Ø¯Ø§Ø¯ Ù‡Ø± Ú©Ù„Ø§Ø³
label_counts = df_final.groupBy("label").count().toPandas().set_index("label")["count"].to_dict()

# Ø³Ø§Ø®Øª weight Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø±Ø¯ÛŒÙ: weight = 1 / count(label)
weight_expr = when(col("label") == 0, 1.0 / label_counts[0]) \
    .when(col("label") == 1, 1.0 / label_counts[1]) \
    .when(col("label") == 2, 1.0 / label_counts[2]) \
    .when(col("label") == 3, 1.0 / label_counts[3]) \
    .when(col("label") == 4, 1.0 / label_counts[4]) \
    .otherwise(1.0)

# Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† weightColumn
df_weighted = df_final.withColumn("class_weight", weight_expr)

from pyspark.ml.classification import RandomForestClassifier

# ØªÙ‚Ø³ÛŒÙ… Ø¨Ø§ ÙˆØ²Ù†
train_data, test_data = df_weighted.randomSplit([0.8, 0.2], seed=42)

# Ù…Ø¯Ù„ Ø¨Ø§ ÙˆØ²Ù†â€ŒØ¯Ù‡ÛŒ
rf = RandomForestClassifier(
    labelCol="label",
    featuresCol="features",
    weightCol="class_weight",    #  Ø§ÛŒÙ† Ø®Ø· Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯Ù‡
    numTrees=200,
    maxDepth=12,
    subsamplingRate=0.85,
    featureSubsetStrategy="auto"
)

model = rf.fit(train_data)
predictions = model.transform(test_data)

predictions.select("prediction", "label").show(10)

# 4. Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ú†Ù†Ø¯Ù…Ø¹ÛŒØ§Ø±ÛŒ Ø¯Ø± PySpark
eval_acc = MulticlassClassificationEvaluator(labelCol="label", predictionCol="prediction", metricName="accuracy")
eval_f1 = MulticlassClassificationEvaluator(labelCol="label", predictionCol="prediction", metricName="f1")
eval_prec = MulticlassClassificationEvaluator(labelCol="label", predictionCol="prediction", metricName="weightedPrecision")
eval_rec = MulticlassClassificationEvaluator(labelCol="label", predictionCol="prediction", metricName="weightedRecall")

print(f" Accuracy       : {eval_acc.evaluate(predictions):.4f}")
print(f" F1 Score       : {eval_f1.evaluate(predictions):.4f}")
print(f" Precision      : {eval_prec.evaluate(predictions):.4f}")
print(f" Recall         : {eval_rec.evaluate(predictions):.4f}")

# 5. Confusion Matrix (Ø¨Ø§ ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ pandas)
y_true = predictions.select("label").toPandas()
y_pred = predictions.select("prediction").toPandas()
cm = confusion_matrix(y_true, y_pred, labels=[0,1,2,3,4])

plt.figure(figsize=(8,6))
sns.heatmap(cm, annot=True, fmt="d", cmap="YlGnBu", xticklabels=[0,1,2,3,4], yticklabels=[0,1,2,3,4])
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix (Enhanced RandomForest)")
plt.show()

"""### Ø´Ø¨Ú©Ù‡ Ø¹ØµØ¨ÛŒ MultilayerPerceptronClassifier Ø¨Ø§ Ø³Ø§Ø®ØªØ§Ø± Pipeline"""

!pip install pyspark

from pyspark.sql import SparkSession

# Ø§ÛŒØ¬Ø§Ø¯ SparkSession
spark = SparkSession.builder.appName("SchemaInspection").getOrCreate()

# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¬Ø¯Ø¯ Ø¯Ø§Ø¯Ù‡
df = spark.read.csv("/content/heart_disease_uci.csv", header=True, inferSchema=True)

# Ù†Ù…Ø§ÛŒØ´ Ø³Ø§Ø®ØªØ§Ø± Ø³ØªÙˆÙ†â€ŒÙ‡Ø§
df.printSchema()

from pyspark.sql import SparkSession
from pyspark.ml.feature import StringIndexer, VectorAssembler, StandardScaler
from pyspark.ml import Pipeline
from pyspark.ml.classification import RandomForestClassifier
from pyspark.ml.evaluation import MulticlassClassificationEvaluator
from sklearn.metrics import classification_report, confusion_matrix
import pandas as pd

# 1. Ø´Ø±ÙˆØ¹ Spark
spark = SparkSession.builder.master("local[*]").appName("HeartDiseaseRF").getOrCreate()

# 2. Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡
df = spark.read.csv("/content/heart_disease_uci.csv", header=True, inferSchema=True)

# 3. Ù¾Ø§Ú©â€ŒØ³Ø§Ø²ÛŒ Ùˆ Ù¾Ø±Ú©Ø±Ø¯Ù† null
df = df.fillna({
    "ca": -1, "thalch": -1, "oldpeak": -1, "trestbps": -1,
    "chol": -1, "fbs": 0, "exang": 0,
    "sex": "unknown", "cp": "unknown", "restecg": "unknown",
    "slope": "unknown", "thal": "unknown", "dataset": "unknown"
})

# 4. Ù…Ø´Ø®Øµ Ú©Ø±Ø¯Ù† ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§
categorical_cols = ["sex", "cp", "restecg", "slope", "thal", "dataset"]
numerical_cols = ["age", "trestbps", "chol", "fbs", "thalch", "exang", "oldpeak", "ca"]
label_col = "num"

# 5. Index Ú©Ø±Ø¯Ù† ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…ØªÙ†ÛŒ
indexers = [StringIndexer(inputCol=col, outputCol=col + "_indexed", handleInvalid="keep") for col in categorical_cols]

# 6. ØªØ±Ú©ÛŒØ¨ Ù‡Ù…Ù‡ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§
feature_cols = [col + "_indexed" for col in categorical_cols] + numerical_cols
assembler = VectorAssembler(inputCols=feature_cols, outputCol="features_raw", handleInvalid="keep")
scaler = StandardScaler(inputCol="features_raw", outputCol="features")

# 7. Ù…Ø¯Ù„ RandomForest Ø¨Ø§ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ù‚ÙˆÛŒâ€ŒØªØ±
rf = RandomForestClassifier(labelCol=label_col, featuresCol="features", numTrees=200, maxDepth=10, maxBins=64)

# 8. Ø³Ø§Ø®Øª Pipeline
pipeline = Pipeline(stages=indexers + [assembler, scaler, rf])

# 9. ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
train_data, test_data = df.randomSplit([0.8, 0.2], seed=42)

# 10. Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„
model = pipeline.fit(train_data)

# 11. Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ
predictions = model.transform(test_data)

# 12. Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø¯Ù‚Øª
evaluator = MulticlassClassificationEvaluator(labelCol=label_col, predictionCol="prediction", metricName="accuracy")
accuracy = evaluator.evaluate(predictions)

# 13. Ù†Ù…Ø§ÛŒØ´ Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§
print(f"\nâœ… Accuracy       : {accuracy:.4f}")

# ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Pandas
y_true = predictions.select(label_col).toPandas()
y_pred = predictions.select("prediction").toPandas()

# Ù†Ù…Ø§ÛŒØ´ Ú¯Ø²Ø§Ø±Ø´
print("ğŸ¯ F1 Score       :", f"{classification_report(y_true, y_pred, output_dict=True)['weighted avg']['f1-score']:.4f}")
print("ğŸ§­ Precision      :", f"{classification_report(y_true, y_pred, output_dict=True)['weighted avg']['precision']:.4f}")
print("ğŸ§ª Recall         :", f"{classification_report(y_true, y_pred, output_dict=True)['weighted avg']['recall']:.4f}")

print("\nğŸ“Š Confusion Matrix:")
print(confusion_matrix(y_true, y_pred))

print("\nğŸ“„ Classification Report:")
print(classification_report(y_true, y_pred))

"""### Undersampling Ø¨Ø§Ø¹Ø« Ø§Ø² Ø¯Ø³Øª Ø±ÙØªÙ† Ø§Ø·Ù„Ø§Ø¹Ø§Øª"""

from pyspark.sql.functions import col
from pyspark.ml.classification import RandomForestClassifier
from pyspark.ml.evaluation import MulticlassClassificationEvaluator
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# 1. Ù…ØªØ¹Ø§Ø¯Ù„â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§: undersample Ú©Ù„Ø§Ø³ 0
minor_classes = df_final.filter(col("label") != 0)
major_class_sample = df_final.filter(col("label") == 0).sample(withReplacement=False, fraction=0.35, seed=42)
balanced_df = minor_classes.union(major_class_sample)

# 2. ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
train_data, test_data = balanced_df.randomSplit([0.8, 0.2], seed=42)

# 3. Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Ø¬Ù†Ú¯Ù„ ØªØµØ§Ø¯ÙÛŒ
rf = RandomForestClassifier(labelCol="label", featuresCol="features", numTrees=100, maxDepth=8)
model = rf.fit(train_data)

# 4. Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ
predictions = model.transform(test_data)
predictions.select("prediction", "label").show(10)

# 5. Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯
eval_acc = MulticlassClassificationEvaluator(labelCol="label", predictionCol="prediction", metricName="accuracy")
eval_f1 = MulticlassClassificationEvaluator(labelCol="label", predictionCol="prediction", metricName="f1")
eval_prec = MulticlassClassificationEvaluator(labelCol="label", predictionCol="prediction", metricName="weightedPrecision")
eval_rec = MulticlassClassificationEvaluator(labelCol="label", predictionCol="prediction", metricName="weightedRecall")

print(f" Accuracy       : {eval_acc.evaluate(predictions):.4f}")
print(f" F1 Score       : {eval_f1.evaluate(predictions):.4f}")
print(f" Precision      : {eval_prec.evaluate(predictions):.4f}")
print(f" Recall         : {eval_rec.evaluate(predictions):.4f}")

# 6. Confusion Matrix
y_true = predictions.select("label").toPandas()
y_pred = predictions.select("prediction").toPandas()
cm = confusion_matrix(y_true, y_pred, labels=[0,1,2,3,4])

plt.figure(figsize=(8,6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=[0,1,2,3,4], yticklabels=[0,1,2,3,4])
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()

# 7. Ú¯Ø²Ø§Ø±Ø´ Ù…ØªÙ†ÛŒ Ú©Ø§Ù…Ù„
print("\nğŸ“„ Classification Report:")
print(classification_report(y_true, y_pred, digits=3))

"""### ØªØ¨Ø¯ÛŒÙ„ Ù…Ø³Ø¦Ù„Ù‡ Ø¨Ù‡ Binary Classification"""

from pyspark.sql.functions import when, col
from pyspark.ml.classification import RandomForestClassifier
from pyspark.ml.evaluation import BinaryClassificationEvaluator
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

#  1. ØªØ¨Ø¯ÛŒÙ„ label Ø¨Ù‡ Ø¨Ø§ÛŒÙ†Ø±ÛŒ: 0 = Ø³Ø§Ù„Ù…ØŒ 1 = Ø¨ÛŒÙ…Ø§Ø±
binary_df = df_final.withColumn("binary_label", when(col("label") == 0, 0).otherwise(1))

#  2. ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø¯ÙˆÙ† Ø­Ø°Ù Ù‡ÛŒÚ†â€ŒÚ†ÛŒØ²
train_data, test_data = binary_df.randomSplit([0.8, 0.2], seed=42)

#  3. Ù…Ø¯Ù„ Random Forest Ø¨Ø§ÛŒÙ†Ø±ÛŒ
rf = RandomForestClassifier(labelCol="binary_label", featuresCol="features", numTrees=100, maxDepth=8)
model = rf.fit(train_data)

#  4. Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ
predictions = model.transform(test_data)
predictions.select("prediction", "binary_label").show(10)

#  5. Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø¨Ø§ BinaryClassificationEvaluator
evaluator = BinaryClassificationEvaluator(labelCol="binary_label", rawPredictionCol="rawPrediction", metricName="areaUnderROC")
roc_auc = evaluator.evaluate(predictions)

print(f" ROC AUC: {roc_auc:.4f}")

#  6. Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ø¯Ù‚ÛŒÙ‚â€ŒØªØ±
y_true = predictions.select("binary_label").toPandas()
y_pred = predictions.select("prediction").toPandas()

cm = confusion_matrix(y_true, y_pred, labels=[0,1])
plt.figure(figsize=(6,5))
sns.heatmap(cm, annot=True, fmt="d", cmap="Greens", xticklabels=["Healthy", "Disease"], yticklabels=["Healthy", "Disease"])
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Binary Confusion Matrix")
plt.show()

print("\n Binary Classification Report:")
print(classification_report(y_true, y_pred, target_names=["Healthy", "Disease"], digits=3))

from pyspark.ml.classification import DecisionTreeClassifier
from pyspark.ml.evaluation import MulticlassClassificationEvaluator
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
from pyspark.sql.functions import col

# 1. Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ØªÙ…Ø§Ù… Ø¯Ø§Ø¯Ù‡ Ø¨Ø¯ÙˆÙ† Ø­Ø°Ù
train_data, test_data = df_final.randomSplit([0.8, 0.2], seed=42)

# 2. Ù…Ø¯Ù„ Decision Tree Ø¨Ø±Ø§ÛŒ Ú†Ù†Ø¯Ú©Ù„Ø§Ø³Ù‡
dt = DecisionTreeClassifier(labelCol="label", featuresCol="features", maxDepth=8)
model = dt.fit(train_data)

# 3. Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ
predictions = model.transform(test_data)
predictions.select("prediction", "label").show(10)

# 4. Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ
eval_acc = MulticlassClassificationEvaluator(labelCol="label", predictionCol="prediction", metricName="accuracy")
eval_f1 = MulticlassClassificationEvaluator(labelCol="label", predictionCol="prediction", metricName="f1")
eval_prec = MulticlassClassificationEvaluator(labelCol="label", predictionCol="prediction", metricName="weightedPrecision")
eval_rec = MulticlassClassificationEvaluator(labelCol="label", predictionCol="prediction", metricName="weightedRecall")

print(f" Accuracy       : {eval_acc.evaluate(predictions):.4f}")
print(f" F1 Score       : {eval_f1.evaluate(predictions):.4f}")
print(f" Precision      : {eval_prec.evaluate(predictions):.4f}")
print(f" Recall         : {eval_rec.evaluate(predictions):.4f}")

# 5. Confusion Matrix
y_true = predictions.select("label").toPandas()
y_pred = predictions.select("prediction").toPandas()
cm = confusion_matrix(y_true, y_pred, labels=[0,1,2,3,4])

plt.figure(figsize=(8,6))
sns.heatmap(cm, annot=True, fmt="d", cmap="YlGnBu", xticklabels=[0,1,2,3,4], yticklabels=[0,1,2,3,4])
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Multi-class Confusion Matrix")
plt.show()

# 6. Ú¯Ø²Ø§Ø±Ø´ Ø¯Ù‚ÛŒÙ‚â€ŒØªØ±
print("\n Multi-class Classification Report:")
print(classification_report(y_true, y_pred, digits=3))

"""### XGBoost"""

# Ù†ØµØ¨ XGBoost Ø¯Ø± Colab
!pip install -q xgboost

# 1. Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡
import pandas as pd
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import xgboost as xgb
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv("/content/heart_disease_uci.csv")

# 2. Ø­Ø°Ù ID Ùˆ Ø¨Ø±Ø±Ø³ÛŒ NA
df = df.drop(columns=["id"], errors="ignore")
df = df.dropna()

# 3. Label Encoding Ø¨Ø±Ø§ÛŒ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù…ØªÙ†ÛŒ
label_cols = df.select_dtypes(include="object").columns
le_dict = {}
for col in label_cols:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col])
    le_dict[col] = le

# 4. ØªØ¹Ø±ÛŒÙ X Ùˆ y
X = df.drop("num", axis=1)
y = df["num"]  # Ú†Ù†Ø¯Ú©Ù„Ø§Ø³Ù‡: 0 ØªØ§ 4

# 5. ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)

# 6. Ù…Ø¯Ù„ XGBoost
model = xgb.XGBClassifier(
    objective='multi:softprob',
    num_class=5,
    eval_metric='mlogloss',
    use_label_encoder=False,
    max_depth=5,
    n_estimators=100,
    learning_rate=0.1
)
model.fit(X_train, y_train)

# 7. Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ùˆ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ
y_pred = model.predict(X_test)
print(f" Accuracy: {accuracy_score(y_test, y_pred):.4f}\n")
print(" Classification Report:")
print(classification_report(y_test, y_pred, digits=3))

# 8. Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8,6))
sns.heatmap(cm, annot=True, fmt="d", cmap="YlGnBu", xticklabels=range(5), yticklabels=range(5))
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix (XGBoost Multi-class)")
plt.show()

"""### OverSample + class_weight"""

!pip install -q imbalanced-learn

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from imblearn.over_sampling import SMOTE
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder

# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡
df = pd.read_csv("/content/heart_disease_uci.csv")
df = df.drop(columns=["id"], errors="ignore").dropna()

# Label Encoding
for col in df.select_dtypes("object").columns:
    df[col] = LabelEncoder().fit_transform(df[col])

X = df.drop("num", axis=1)
y = df["num"]

# SMOTE Ø±ÙˆÛŒ Ú©Ù„ Ø¯Ø§Ø¯Ù‡
sm = SMOTE(random_state=42)
X_resampled, y_resampled = sm.fit_resample(X, y)

# ØªÙ‚Ø³ÛŒÙ… train/test
X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled)

# Ù…Ø¯Ù„ Ø¬Ù†Ú¯Ù„ ØªØµØ§Ø¯ÙÛŒ Ø¨Ø§ ÙˆØ²Ù†â€ŒØ¯Ù‡ÛŒ Ø®ÙˆØ¯Ú©Ø§Ø±
rf = RandomForestClassifier(class_weight='balanced', n_estimators=100, max_depth=8, random_state=42)
rf.fit(X_train, y_train)

# Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ
y_pred = rf.predict(X_test)
print(f" Accuracy: {accuracy_score(y_test, y_pred):.4f}\n")
print(" Classification Report:")
print(classification_report(y_test, y_pred, digits=3))

# Ù…Ø§ØªØ±ÛŒØ³ Ø®Ø·Ø§
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8,6))
sns.heatmap(cm, annot=True, fmt="d", cmap="BuGn", xticklabels=range(5), yticklabels=range(5))
plt.xlabel("Predicted")
plt.ylabel("True")
plt.title("Confusion Matrix (RF + SMOTE + Class Weights)")
plt.show()

"""# **2-**

# Extra Point
"""

!pkill -f Worker
!pkill -f Master

!rm -rf /content/spark-worker-1 /content/spark-worker-2

!/content/spark-3.1.2-bin-hadoop2.7/sbin/start-master.sh
!hostname

!nohup /content/spark-3.1.2-bin-hadoop2.7/sbin/start-worker.sh \
  --webui-port 8081 \
  --work-dir /content/spark-worker-1 \
  spark://f618f15ce7f4:7077 > /dev/null 2>&1 &

!nohup /content/spark-3.1.2-bin-hadoop2.7/sbin/start-worker.sh \
  --webui-port 8082 \
  --work-dir /content/spark-worker-2 \
  spark://f618f15ce7f4:7077 > /dev/null 2>&1 &

!jps

!ls /content/spark-3.1.2-bin-hadoop2.7/logs/
!ps -ef | grep spark | grep Worker

import findspark
findspark.init()

from pyspark.sql import SparkSession

# Ø§ØªØµØ§Ù„ Ø¨Ù‡ Master Ø¯Ø± Ø­Ø§Ù„Øª Cluster
spark = SparkSession.builder \
    .appName("HeartDiseaseClassification") \
    .master("spark://f618f15ce7f4:7077") \
    .config("spark.executor.memory", "1g") \
    .config("spark.driver.memory", "1g") \
    .getOrCreate()

df = spark.read.csv("/content/heart_disease_uci.csv", header=True, inferSchema=True)
df.printSchema()
df.show(5)

from pyspark.sql.functions import col
from pyspark.ml.feature import StringIndexer, VectorAssembler
from pyspark.ml import Pipeline

df = df.dropna(how="any")  # Ø­Ø°Ù Ø±Ø¯ÛŒÙâ€ŒÙ‡Ø§ÛŒ Ù†Ø§Ù‚Øµ

# Ø­Ø°Ù Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø¨ÛŒâ€ŒÙ…ØµØ±Ù
df = df.drop("id", "dataset")

# Ø³ØªÙˆÙ† Ù‡Ø¯Ù (label)
label_col = "num"

# Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø¹Ø¯Ø¯ÛŒ (Ø¨Ù‡ Ø¬Ø² label)
numeric_cols = ['age', 'trestbps', 'chol', 'thalch', 'oldpeak', 'ca']

# Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Boolean (True/False)
boolean_cols = ['fbs', 'exang']

# Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù…ØªÙ†ÛŒ Ú©Ù‡ Ø¨Ø§ÛŒØ¯ index Ø¨Ø´Ù†
categorical_cols = ['sex', 'cp', 'restecg', 'slope', 'thal']

# StringIndexer Ø¨Ø±Ø§ÛŒ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù…ØªÙ†ÛŒ
indexers = [StringIndexer(inputCol=col, outputCol=col + "_idx", handleInvalid="keep") for col in categorical_cols]

# Index Ú©Ø±Ø¯Ù† Ø³ØªÙˆÙ† Ù‡Ø¯Ù (Ø¯Ø± ØµÙˆØ±Øª Ù†ÛŒØ§Ø²ØŒ ÙˆÙ„ÛŒ Ú†ÙˆÙ† num Ø¹Ø¯Ø¯ÛŒÙ‡ØŒ Ù„Ø§Ø²Ù… Ù†ÛŒØ³Øª)
# Ø§Ú¯Ø± Ø¨Ø®ÙˆØ§ÛŒ Ú©Ù„Ø§Ø³â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø§ÛŒÙ†Ø±ÛŒ Ú©Ù†ÛŒ (0 vs Ø¨Ù‚ÛŒÙ‡)ØŒ Ø§ÛŒÙ†Ø¬Ø§ Ù…ÛŒâ€ŒØªÙˆÙ†ÛŒ Ø§ÙˆÙ† Ú©Ø§Ø±Ùˆ Ø¨Ú©Ù†ÛŒ

# ØªÙ…Ø§Ù… ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ Ù†Ù‡Ø§ÛŒÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„
final_features = numeric_cols + boolean_cols + [c + "_idx" for c in categorical_cols]

# Ø¨Ø±Ø¯Ø§Ø±Ø³Ø§Ø²
assembler = VectorAssembler(inputCols=final_features, outputCol="features")

# Pipeline Ú©Ø§Ù…Ù„
pipeline = Pipeline(stages=indexers + [assembler])
processed_df = pipeline.fit(df).transform(df).select("features", col(label_col).alias("label"))

# Ù†Ù…Ø§ÛŒØ´ Ù†Ù…ÙˆÙ†Ù‡â€ŒØ§ÛŒ Ø§Ø² Ø¯Ø§Ø¯Ù‡ Ù†Ù‡Ø§ÛŒÛŒ
processed_df.show(5, truncate=False)

train_data, test_data = processed_df.randomSplit([0.8, 0.2], seed=42)

# from pyspark.ml.classification import DecisionTreeClassifier
# dt = DecisionTreeClassifier(labelCol="label", featuresCol="features")

from pyspark.ml.classification import RandomForestClassifier
rf = RandomForestClassifier(labelCol="label", featuresCol="features", numTrees=100, maxDepth=10)

model = rf.fit(train_data)

predictions = model.transform(test_data)

from pyspark.ml.evaluation import MulticlassClassificationEvaluator

evaluator = MulticlassClassificationEvaluator(labelCol="label", predictionCol="prediction", metricName="accuracy")
accuracy = evaluator.evaluate(predictions)

f1 = MulticlassClassificationEvaluator(labelCol="label", predictionCol="prediction", metricName="f1").evaluate(predictions)
precision = MulticlassClassificationEvaluator(labelCol="label", predictionCol="prediction", metricName="weightedPrecision").evaluate(predictions)
recall = MulticlassClassificationEvaluator(labelCol="label", predictionCol="prediction", metricName="weightedRecall").evaluate(predictions)

print(f" Accuracy in Cluster Mode : {accuracy:.4f}")
print(f" F1 Score in Cluster Mode: {f1:.4f}")
print(f" Precision in Cluster Mode: {precision:.4f}")
print(f" Recall in Cluster Mode: {recall:.4f}")

"""Ø¨Ø§ 2 Ú©Ù„Ø§Ø³Ù‡"""

from pyspark.sql.functions import col, when
from pyspark.ml.feature import StringIndexer, VectorAssembler
from pyspark.ml import Pipeline
from pyspark.ml.classification import GBTClassifier
from pyspark.ml.evaluation import MulticlassClassificationEvaluator

# Ø­Ø°Ù Ø¯Ø§Ø¯Ù‡ Ù†Ø§Ù‚Øµ Ùˆ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø¨ÛŒâ€ŒÙ…ØµØ±Ù
df = df.dropna(how="any")
df = df.drop("id", "dataset")

#  ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ classification Ø¯ÙˆØªØ§ÛŒÛŒ: 0 = Ø³Ù„Ø§Ù…Øª | 1 = Ø¨ÛŒÙ…Ø§Ø±
df = df.withColumn("label", when(col("num") == 0, 0).otherwise(1))

# ØªØ¹ÛŒÛŒÙ† Ø³ØªÙˆÙ†â€ŒÙ‡Ø§
numeric_cols = ['age', 'trestbps', 'chol', 'thalch', 'oldpeak', 'ca']
boolean_cols = ['fbs', 'exang']
categorical_cols = ['sex', 'cp', 'restecg', 'slope', 'thal']

# Ø³Ø§Ø®Øª pipeline
indexers = [StringIndexer(inputCol=c, outputCol=c + "_idx", handleInvalid="keep") for c in categorical_cols]
final_features = numeric_cols + boolean_cols + [c + "_idx" for c in categorical_cols]
assembler = VectorAssembler(inputCols=final_features, outputCol="features")
pipeline = Pipeline(stages=indexers + [assembler])

# Ù¾Ø±Ø¯Ø§Ø²Ø´
processed_df = pipeline.fit(df).transform(df).select("features", "label")
train_data, test_data = processed_df.randomSplit([0.8, 0.2], seed=42)

#  Ù…Ø¯Ù„ GBTClassifier (Ø¯Ø±Ø®Øª ØªÙ‚ÙˆÛŒØªÛŒ)
gbt = GBTClassifier(labelCol="label", featuresCol="features", maxIter=100, maxDepth=5, stepSize=0.1, seed=42)
model = gbt.fit(train_data)
predictions = model.transform(test_data)

#  Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ
evaluator_acc = MulticlassClassificationEvaluator(labelCol="label", predictionCol="prediction", metricName="accuracy")
evaluator_f1  = MulticlassClassificationEvaluator(labelCol="label", predictionCol="prediction", metricName="f1")
evaluator_pre = MulticlassClassificationEvaluator(labelCol="label", predictionCol="prediction", metricName="weightedPrecision")
evaluator_rec = MulticlassClassificationEvaluator(labelCol="label", predictionCol="prediction", metricName="weightedRecall")

print(" Accuracy       :", round(evaluator_acc.evaluate(predictions), 4))
print(" F1 Score       :", round(evaluator_f1.evaluate(predictions), 4))
print(" Precision      :", round(evaluator_pre.evaluate(predictions), 4))
print(" Recall         :", round(evaluator_rec.evaluate(predictions), 4))

"""Ø§Ú¯Ù…Ù†ØªÛŒØ´Ù†"""

from pyspark.sql.functions import rand
from pyspark.sql import DataFrame

# ØªØ§Ø¨Ø¹ oversample Ú©Ø±Ø¯Ù† Ú©Ù„Ø§Ø³ Ù‡Ø¯Ù Ø¨Ù‡ Ù…Ù‚Ø¯Ø§Ø± Ø¯Ù„Ø®ÙˆØ§Ù‡
def oversample(df: DataFrame, target_class: int, factor: int) -> DataFrame:
    small_df = df.filter(df.label == target_class)
    oversampled = small_df.sample(withReplacement=True, fraction=factor, seed=42)
    return oversampled

# Ø´Ù…Ø§Ø±Ø´ Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§
df_counts = processed_df.groupBy("label").count().orderBy("label")
df_counts.show()

# Ø¯Ø§Ø¯Ù‡â€ŒØ§ÙØ²Ø§ÛŒÛŒ Ø¨Ø±Ø§ÛŒ Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ÛŒ Ø¨Ø§ ØªØ¹Ø¯Ø§Ø¯ Ú©Ù…
augmented_dfs = [processed_df]  # Ø´Ø±ÙˆØ¹ Ø¨Ø§ Ú©Ù„ Ø¯ÛŒØªØ§
augmentation_factors = {1: 2.5, 2: 3.0, 3: 3.5}  # Ú©Ù„Ø§Ø³ 0 Ù†ÛŒØ§Ø²ÛŒ Ù†Ø¯Ø§Ø±Ù‡

for label, factor in augmentation_factors.items():
    augmented_dfs.append(oversample(processed_df, label, factor))

# ØªØ¬Ù…ÛŒØ¹ Ù†Ù‡Ø§ÛŒÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø§ÙØ²ÙˆØ¯Ù‡ Ø´Ø¯Ù‡
balanced_df = augmented_dfs[0]
for aug_df in augmented_dfs[1:]:
    balanced_df = balanced_df.union(aug_df)

# Ø¨Ø±Ø±Ø³ÛŒ ØªÙˆØ§Ø²Ù† Ù†Ù‡Ø§ÛŒÛŒ
balanced_df.groupBy("label").count().orderBy("label").show()


from pyspark.ml.classification import RandomForestClassifier
from pyspark.ml.evaluation import MulticlassClassificationEvaluator

# ØªÙ‚Ø³ÛŒÙ… Ø¢Ù…ÙˆØ²Ø´ Ùˆ ØªØ³Øª
train_data, test_data = balanced_df.randomSplit([0.8, 0.2], seed=42)

# Ù…Ø¯Ù„ Random Forest
rf = RandomForestClassifier(labelCol="label", featuresCol="features", numTrees=150, maxDepth=10)
model = rf.fit(train_data)
predictions = model.transform(test_data)

# Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù†Ù‡Ø§ÛŒÛŒ
evaluator = MulticlassClassificationEvaluator(labelCol="label", predictionCol="prediction")
acc = evaluator.evaluate(predictions, {evaluator.metricName: "accuracy"})
f1 = evaluator.evaluate(predictions, {evaluator.metricName: "f1"})
precision = evaluator.evaluate(predictions, {evaluator.metricName: "weightedPrecision"})
recall = evaluator.evaluate(predictions, {evaluator.metricName: "weightedRecall"})

print(f" Accuracy (Augmented)  : {acc:.4f}")
print(f" F1 Score (Augmented)  : {f1:.4f}")
print(f" Precision (Augmented) : {precision:.4f}")
print(f" Recall (Augmented)    : {recall:.4f}")